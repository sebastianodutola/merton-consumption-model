{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following HJB:\n",
    "\n",
    "$$\n",
    "0 = \\sup_{(\\pi,c)\\in \\mathcal{U}} \\left\\{ \\partial_tV(w,t) + \\partial_wV(w,t)\\cdot(r + \\pi_t(\\mu-r)w - c_t) + \\frac{1}{2}\\partial_{ww}Vw^2\\pi_t^2\\sigma^2 + e^{-\\rho t}U(c_t,t) \\right\\}, \\quad w\\geq0, w_0\\geq 0, c_t \\geq 0\n",
    "$$\n",
    "\n",
    "An closed-form solution can be found for specific $U(c,t)$ for example those with constant relative risk-aversion $U(c, t) = \\frac{c^{1-\\gamma}}{1-\\gamma}$.\n",
    "However, for more complicated utility functions a numerical solver is needed. \n",
    "\n",
    "One way fo doing this is using finite differences. Since the equation has a terminal condition our first instinct is to use an implicit scheme. While it is possible to create an explicit scheme by changing variables to $\\tau = T-t$, we remember from numerical analysis that such a scheme may face stability issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implicit scheme is as follows: \n",
    "\n",
    "### Step 1: Finite Differences\n",
    "- discretise the spatial variable linearly: $w_j = 0 + j\\Delta w$, with $j = 0,...,N$, $w_N = w_{max}$ for suitably large $w_{max}$.\n",
    "- discretise the time variable linearly: $t_k = t_0 + k\\Delta t$ with $k = 0,...,M$, $t_M = T$. For simplicity we take t_0 = 0 W.L.O.G.\n",
    "- We use central difference for the 2nd order derivative and an upwinding derivative for the advection (1st order derivative) term to ensure stability.\n",
    "\n",
    "Let $v_j^k$ be the value function evaluated at grid point $(w_j, t_k)$, $\\alpha_j$ be the advection coefficient evaluated at $w_j$, $d_j$ the diffusion coefficient evaluated at $w_j$, and $\\Theta^k$ be the constant term.\n",
    "$$\\begin{align*}\n",
    "\\alpha_j(\\pi,c) &:= r + \\pi(\\mu -r)w_j - c \\\\\n",
    "d_j(\\pi,c) &:= \\frac{1}{2}w_j^2\\pi^2\\sigma^2 \\\\\n",
    "\\Theta^k(\\pi,c) &:= e^{-\\rho t_{k}}U(c,t_{k})\n",
    "\\end{align*}$$\n",
    "\n",
    "The standard backward Euler scheme for the HJB is thus:\n",
    "\n",
    "$$\\frac{v^{k}_j - v^{k-1}_j}{\\Delta t} = - \\sup_{(\\pi,c)}\\left[ D^{up}_w(v^{k-1}_j)\\alpha_j(\\pi,c) + D^+_wD^-_w(v^{k-1}_j)d_j(\\pi,c)+ \\Theta^{k-1}(\\pi,c)\\right]$$\n",
    "\n",
    "Where:\n",
    "- $D^{up}_w$ is the forward difference operator $D^+_w(v^k_j) = \\frac{v^k_{j+1} - v^k_{j}}{\\Delta w}$ if $\\alpha_j <0$, and $D^-_w(v^k_j) = \\frac{v^k_{j} - v^k_{j-1}}{\\Delta w}$ if $\\alpha_j >0$\n",
    "- $D^+_wD^-_w$ is the second order central difference operator $D^+_wD^-_w(v^k)_{j} = \\frac{v^k_{j+1} - 2v^k_{j} + v^k_{j-1}}{(\\Delta w)^2}$ \n",
    "\n",
    "Taking the supremum accross the admissable set of controls is a non-linear optimisation problem because the diffusion term is quadratic in $\\pi$. Therefore, we rely on policy iteration in order to find the optimal control at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Policy Iteration\n",
    "\n",
    "Policy Iteration is a form of reinforcement learning used for iteratively choosing optimal control. At the PDE level policy iteration can be shown to converge on the optimal policy. If sufficiently careful with what discretisation you take, this convergence carries over to our finite difference scheme.\n",
    "\n",
    "In practice we guess a policy at the required timestep, evaluate the value function given the policy, then find a new optimal policy based on that evaluation. We use an extra subscript to indicate the policy iteration. Let the inital guess policy be $(\\pi_0, c_0)$. Let $v^{*k}_j$ denote the optimal value function determined from the previous time step.\n",
    "\n",
    "$$\\frac{v^{*k}_j - v^{k-1}_{j,0}}{\\Delta t} = - \\left[ D^{up}_w(v^{k-1}_{j,0})\\alpha_j(\\pi_0, c_0) + D^+_wD^-_w(v^{k-1}_{j,0})d_j(\\pi_0, c_0)+ \\Theta_{j}^{k-1}(\\pi_0, c_0)\\right]$$\n",
    "\n",
    "This yields a linear system of equations we can solve for $\\mathbf{v^{k-1}_0}$. We then find the optimal policy w.r.t the resulting value function. This is a non-linear optimisation problem.\n",
    "\n",
    "$$(\\pi_1,c_1) = \\argmax_{(\\pi,c)} \\left[ D^{up}_w(v^{k-1}_{j,0})\\alpha_j(\\pi_0, c_0) + D^+_wD^-_w(v^{k-1}_{j,0})d_j(\\pi_0, c_0)+ \\Theta_{j}^{k-1}(\\pi_0, c_0)\\right]$$ \n",
    "\n",
    "We iterate this process until $||\\mathbf{v^{k-1}_n}-\\mathbf{v^{k-1}_{n-1}}|| < \\epsilon $ and:\n",
    "\n",
    "$$(\\pi^*, c^*) := (\\pi_{n+1}, c_{n+1}) = \\argmax_{(\\pi,c)} \\left[ D^{up}_w(v^{k-1}_{j,n})\\alpha_j(\\pi_{n}, c_{n}) + D^+_wD^-_w(v^{k-1}_{j,n})d_j(\\pi_{n}, c_{n})+ \\Theta_{j}^{k-1}(\\pi_{n}, c_{n})\\right]$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "we can write the difference equation as \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{v^{*k}_{j} - v^{k-1}_{j,n}}{\\Delta t} &= - \\left[ \\left(\\frac{\\alpha_j(\\pi_{n-1}, c_{n-1})}{\\Delta w} + \\frac{d_j(\\pi_{n-1}, c_{n-1})}{(\\Delta w)^2}\\right)v^{k-1}_{j+1} + \\left(-\\frac{\\alpha_j(\\pi_{n-1}, c_{n-1})}{\\Delta w} - 2\\frac{d_j(\\pi_{n-1}, c_{n-1})}{(\\Delta w)^2}\\right)v^{k-1}_{j} + \\frac{d_j(\\pi_{n-1}, c_{n-1})}{(\\Delta w)^2}v^{k-1}_{j-1} + \\Theta^{k-1}(\\pi_{n-1}, c_{n-1})\\right], \\quad \\text{for } \\alpha_j(\\pi_{n-1}, c_{n-1}) <0\\\\\n",
    "\n",
    "\\frac{v^{*k}_{j} - v^{k-1}_{j,n}}{\\Delta t} &= - \\left[ \\frac{d_j(\\pi_{n-1}, c_{n-1})}{(\\Delta w)^2}v^{k-1}_{j+1} + \\left(\\frac{\\alpha_j(\\pi_{n-1}, c_{n-1})}{\\Delta w} - 2\\frac{d_j(\\pi_{n-1}, c_{n-1})}{(\\Delta w)^2}\\right)v^{k-1}_{j} + \\left(\\frac{d_j(\\pi_{n-1}, c_{n-1})}{(\\Delta w)^2}-\\frac{\\alpha_j(\\pi_{n-1}, c_{n-1})}{\\Delta w}\\right)v^{k-1}_{j-1} + \\Theta^{k-1}(\\pi_{n-1}, c_{n-1})\\right ], \\quad \\text{for } \\alpha_j(\\pi_{n-1}, c_{n-1}) >0\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformulating in matrix notation we define a matrix $\\mathbf{M}$ for $2 \\leq j \\leq N-1$\n",
    "\n",
    "$$\\begin{align*}\n",
    "[M]_{j,j} &= 1 - \\Delta t\\left(\\frac{|\\alpha_j(\\pi_{n-1},c_{n-1})|}{\\Delta w} - 2\\frac{d_j(\\pi_{n-1},c_{n-1})}{(\\Delta w)^2}\\right) \\\\\n",
    "[M]_{j,j+1} &= - \\Delta t\\left(1_{\\alpha<0}\\frac{\\alpha_j(\\pi_{n-1}, c_{n-1})}{\\Delta w} + \\frac{d_j(\\pi_{n-1}, c_{n-1})}{(\\Delta w)^2}\\right) \\\\\n",
    "[M]_{j,j-1} &= - \\Delta t\\left(1_{\\alpha>0}\\frac{d_j(\\pi_{n-1}, c_{n-1})}{(\\Delta w)^2} -\\frac{\\alpha_j(\\pi_{n-1}, c_{n-1})}{\\Delta w} \\right)\\\\\n",
    "[M]_{1,\\cdot} &= [1, 0, 0,...,0]\\\\\n",
    "[M]_{N,\\cdot} &=[0,..., -3,4,-1]\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The first three lines are the difference equations and the final lines encode the Dirichlet boundary conditions at one end and the Neumann boundary conditions at the other. \n",
    "\n",
    "We define the vectors $\\mathbf{v}^{*k}$ and $\\mathbf{v}^{k-1}_{n-1}$\n",
    "$$\n",
    "\\begin{align*}\n",
    "[\\mathbf{v}^{*k}]_j &= v^{*k}_j, \\quad \\text{for } 2 \\leq j \\leq N-1\\\\\n",
    "[\\mathbf{v}^{*k}]_1 &= 0\\\\\n",
    "[\\mathbf{v}^{*k}]_N &= 0\\\\\\\\\n",
    "[\\mathbf{v}^{k-1}_{n-1}] &= v^{k-1}_{j,n-1}, \\quad \\text{for } 1 \\leq j \\leq N\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Finally we define the vector \n",
    "$$\n",
    "\\begin{align*}\n",
    "[\\mathbf{\\Theta}^{k-1}(\\pi_{n-1},c_{n-1})]_j = \\Theta(\\pi_{j,n-1}, c_{j,n-1}), \\quad \\text{for } 1 \\leq j \\leq N-1\\\\\n",
    "[\\mathbf{\\Theta}^{k-1}(\\pi_{n-1},c_{n-1})]_N = 0 \n",
    "\\end{align*}$$\n",
    "\n",
    "Where $(\\pi_{j,n-1}, c_{j,n-1})$ represent the (n-1)th policy iteration at the point $w_j$. \n",
    "\n",
    "And the difference equation becomes \n",
    "$$ \\mathbf{v}^{*k} + \\Delta t\\Theta^{k-1}(\\pi_{n-1},c_{n-1})= M\\mathbf{v}^{k-1}_{n-1} $$\n",
    "\n",
    "Noting that because $C(0,t) = 0$, consumption cannot exceed wealth, the top line reads correctly as the Dirichlet boundary condition and in order to make the bottom line read correctly as the Neumann boundary condition we set the last component of the vector $[\\mathbf{v}^{*k} + \\Delta t\\Theta^{k-1}(\\pi_{n-1},c_{n-1})]_{N}$ to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge. Last sup_norm 8.378978236578405e-06\n",
      "did not converge. Last sup_norm 0.0004422312485985458\n",
      "did not converge. Last sup_norm 0.01330732461065054\n",
      "did not converge. Last sup_norm 0.7237877734005451\n",
      "did not converge. Last sup_norm 17006.709558464587\n",
      "did not converge. Last sup_norm 2076.872369289398\n",
      "did not converge. Last sup_norm 98137.42520618439\n",
      "did not converge. Last sup_norm 43538158.426716805\n",
      "did not converge. Last sup_norm 118075867.6770935\n",
      "did not converge. Last sup_norm 2113607548.4694824\n",
      "did not converge. Last sup_norm 2603855700.1289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/m3x98zjs2bb6cm1g0y7c6v2w0000gn/T/ipykernel_97254/1392433420.py:115: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  return - (D_up * a_j + D_xx * d_j + th)\n",
      "/Users/sebastianodutola/.virtualenvs/merton/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:686: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = [f_eval - f0 for f_eval in f_evals]\n",
      "/Users/sebastianodutola/.virtualenvs/merton/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:687: RuntimeWarning: overflow encountered in divide\n",
      "  df_dx = [delf / delx for delf, delx in zip(df, dx)]\n",
      "/var/folders/c_/m3x98zjs2bb6cm1g0y7c6v2w0000gn/T/ipykernel_97254/1392433420.py:102: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  D_up = (v_right - v_center) / dw\n",
      "/var/folders/c_/m3x98zjs2bb6cm1g0y7c6v2w0000gn/T/ipykernel_97254/1392433420.py:106: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  D_xx = (v_right - 2.0 * v_center + v_left) / (dw ** 2)\n",
      "/var/folders/c_/m3x98zjs2bb6cm1g0y7c6v2w0000gn/T/ipykernel_97254/1392433420.py:148: RuntimeWarning: invalid value encountered in subtract\n",
      "  sup_norm = np.linalg.norm(v_curr - v_new, ord=np.inf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n",
      "did not converge. Last sup_norm nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 170\u001b[39m\n\u001b[32m    167\u001b[39m         \u001b[38;5;66;03m# initial guess for this node\u001b[39;00m\n\u001b[32m    168\u001b[39m         x0 = curr_policy[j, :].copy()\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         res = \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_H\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_curr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_curr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_curr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_sign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_curr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m         curr_policy[j, :] = res.x\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    182\u001b[39m     \u001b[38;5;66;03m# if loop completes without break (no convergence)\u001b[39;00m\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# store last iterate anyway\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/merton/lib/python3.11/site-packages/scipy/optimize/_minimize.py:784\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    781\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    782\u001b[39m                              **options)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    787\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    788\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/merton/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/merton/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:404\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m    403\u001b[39m \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/merton/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:366\u001b[39m, in \u001b[36mScalarFunction._update_grad\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._orig_grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28mself\u001b[39m.g = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[38;5;28mself\u001b[39m.g_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/merton/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:41\u001b[39m, in \u001b[36m_ScalarGradWrapper.__call__\u001b[39m\u001b[34m(self, x, f0, **kwds)\u001b[39m\n\u001b[32m     39\u001b[39m     g = np.atleast_1d(\u001b[38;5;28mself\u001b[39m.grad(np.copy(x), *\u001b[38;5;28mself\u001b[39m.args))\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     g, dct = \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += dct[\u001b[33m'\u001b[39m\u001b[33mnfev\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.ngev += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/merton/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:576\u001b[39m, in \u001b[36mapprox_derivative\u001b[39m\u001b[34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs, full_output, workers)\u001b[39m\n\u001b[32m    572\u001b[39m     \u001b[38;5;66;03m# cannot have a zero step. This might happen if x0 is very large\u001b[39;00m\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# or small. In which case fall back to relative step.\u001b[39;00m\n\u001b[32m    574\u001b[39m     dx = ((x0 + h) - x0)\n\u001b[32m    575\u001b[39m     h = np.where(dx == \u001b[32m0\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m                  \u001b[43m_eps_for_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m *\n\u001b[32m    577\u001b[39m                  sign_x0 * np.maximum(\u001b[32m1.0\u001b[39m, np.abs(x0)),\n\u001b[32m    578\u001b[39m                  h)\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33m2-point\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    581\u001b[39m     h, use_one_sided = _adjust_scheme_to_bounds(\n\u001b[32m    582\u001b[39m         x0, h, \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m1-sided\u001b[39m\u001b[33m'\u001b[39m, lb, ub)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse import diags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# Wealth grid\n",
    "w_max = 1e8\n",
    "N = 50\n",
    "w = np.linspace(0.0, w_max, N)\n",
    "dw = w[1] - w[0]\n",
    "\n",
    "# Time grid\n",
    "T = 100.0\n",
    "t0 = 20.0\n",
    "dt = 0.1\n",
    "t = np.arange(t0, T + 1e-12, dt)   # include endpoint tolerance\n",
    "\n",
    "# Constants\n",
    "gamma = 0.5\n",
    "r = 0.03\n",
    "rho = 0.03\n",
    "sigma = 0.2\n",
    "mu = 0.05\n",
    "\n",
    "# policy iteration constants\n",
    "max_iter = 10\n",
    "tol = 1e-6\n",
    "\n",
    "# Bequest function: returns array of length N evaluated at grid w\n",
    "def B(w_grid, T):\n",
    "    # example: zero bequest\n",
    "    return np.zeros_like(w_grid)\n",
    "\n",
    "# Utility function (vectorized)\n",
    "def U_func(c, t_local):\n",
    "    # ensure no negative consumption\n",
    "    c = np.maximum(c, 0.0)\n",
    "    return np.exp(-rho * t_local) * (c ** (1.0 - gamma)) / (1.0 - gamma)\n",
    "\n",
    "# alpha and d (vectorized)\n",
    "def alpha_func(w_grid, pi, c):\n",
    "    # r - (mu-r) * pi - c\n",
    "    return r - (mu - r) * pi - c\n",
    "\n",
    "def d_func(w_grid, pi, c):\n",
    "    # 0.5 sigma^2 w^2 pi^2\n",
    "    return 0.5 * (sigma ** 2) * (w_grid ** 2) * (pi ** 2)\n",
    "\n",
    "# theta: local term inside the RHS / Hamiltonian (vectorized)\n",
    "def theta_func(pi, c, t_local):\n",
    "    return U_func(c, t_local)\n",
    "\n",
    "# Build M matrix for a given policy: alpha and d are arrays of length N\n",
    "def M_func(alpha_arr, d_arr):\n",
    "    alpha_arr = np.asarray(alpha_arr)\n",
    "    d_arr = np.asarray(d_arr)\n",
    "    if alpha_arr.shape[0] != N or d_arr.shape[0] != N:\n",
    "        raise ValueError(\"alpha and d must have length N\")\n",
    "\n",
    "    M_2 = 1.0 - dt * (np.abs(alpha_arr) / dw - 2.0 * d_arr / (dw ** 2))\n",
    "\n",
    "    M_1 = np.zeros(N)\n",
    "    M_3 = np.zeros(N)\n",
    "    mask_pos = alpha_arr < 0.0\n",
    "    mask_neg = alpha_arr >= 0.0\n",
    "\n",
    "    # alpha >= 0\n",
    "    M_1[mask_neg] = -dt * (alpha_arr[mask_neg] / dw + d_arr[mask_neg] / (dw ** 2))\n",
    "    M_3[mask_neg] = -dt * (d_arr[mask_neg] / (dw ** 2))\n",
    "\n",
    "    # alpha < 0\n",
    "    M_1[mask_pos] = -dt * (d_arr[mask_pos] / (dw ** 2))\n",
    "    M_3[mask_pos] = -dt * (d_arr[mask_pos] / (dw ** 2) - alpha_arr[mask_pos] / dw)\n",
    "\n",
    "    # Build sparse tridiagonal (use LIL for row modification)\n",
    "    A = diags([M_1[1:], M_2, M_3[:-1]], offsets=[-1, 0, 1], shape=(N, N), format=\"lil\")\n",
    "\n",
    "    # Dirichlet at j=0: u(0) = 0 (example)\n",
    "    A[0, :] = 0.0\n",
    "    A[0, 0] = 1.0\n",
    "\n",
    "    # Neumann at j=N-1: use [-3, 4, -1] stencil on last three cols\n",
    "    # ensure N >= 3\n",
    "    if N >= 3:\n",
    "        A[-1, :] = 0.0\n",
    "        A[-1, -3] = -3.0\n",
    "        A[-1, -2] = 4.0\n",
    "        A[-1, -1] = -1.0\n",
    "    else:\n",
    "        raise ValueError(\"N must be at least 3 for the Neumann stencil\")\n",
    "\n",
    "    return A.tocsr()\n",
    "\n",
    "# local Hamiltonian for pointwise minimization\n",
    "# policy: length-2 array [pi, c]\n",
    "# alpha_sign is the alpha from the *current policy evaluation* used to choose upwind direction\n",
    "def local_H(policy, v_left, v_center, v_right, alpha_sign, w_j, t_j):\n",
    "    pi_j, c_j = policy[0], policy[1]\n",
    "\n",
    "    # choose upwind derivative according to alpha_sign (previous policy evaluation)\n",
    "    if alpha_sign < 0:\n",
    "        D_up = (v_right - v_center) / dw\n",
    "    else:\n",
    "        D_up = (v_center - v_left) / dw\n",
    "\n",
    "    D_xx = (v_right - 2.0 * v_center + v_left) / (dw ** 2)\n",
    "\n",
    "    # compute local coefficients for candidate policy\n",
    "    a_j = alpha_func(w_j, pi_j, c_j)\n",
    "    d_j = d_func(w_j, pi_j, c_j)\n",
    "    th = theta_func(pi_j, c_j, t_j)\n",
    "\n",
    "    # Hamiltonian H = D_up * a_j + D_xx * d_j + theta\n",
    "    # minimize returns negative H (we want to maximize)\n",
    "    return - (D_up * a_j + D_xx * d_j + th)\n",
    "\n",
    "# Allocate v and set terminal condition\n",
    "v = np.zeros((len(t), N))\n",
    "v[-1, :] = B(w, T)   # last time row = bequest\n",
    "\n",
    "optimal_policy = np.zeros((len(t), N, 2))\n",
    "\n",
    "# Backward Euler loop over time steps: iterate idx from last index down to 1\n",
    "for idx in range(len(t) - 1, 0, -1):\n",
    "    v_next = v[idx, :].copy()       # value at t_k (known)\n",
    "    v_curr = v_next.copy()          # initial guess for v_{k-1}\n",
    "    curr_policy = np.zeros((N, 2))  # initial policy guess (pi,c)\n",
    "\n",
    "    # choose non-zero initial policy to avoid solution flatlining \n",
    "    curr_policy[:, 0] = 0.5   # example: 50% invested\n",
    "    curr_policy[:, 1] = w * 0.05  # consume 5% of wealth\n",
    "\n",
    "    t_curr = t[idx]                 # time corresponding to v_next\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        pi_n = curr_policy[:, 0]\n",
    "        c_n = curr_policy[:, 1]\n",
    "\n",
    "        alpha_n = alpha_func(w, pi_n, c_n)\n",
    "        d_n = d_func(w, pi_n, c_n)\n",
    "        M_n = M_func(alpha_n, d_n)\n",
    "        U_n = U_func(c_n, t_curr)\n",
    "\n",
    "        # solve linear system (backward Euler)\n",
    "        v_new = spsolve(M_n, v_next + U_n)\n",
    "\n",
    "        # convergence check in sup norm\n",
    "        sup_norm = np.linalg.norm(v_curr - v_new, ord=np.inf)\n",
    "        if sup_norm < tol:\n",
    "            v[idx - 1, :] = v_new\n",
    "            optimal_policy[idx - 1, :, :] = curr_policy\n",
    "            break\n",
    "\n",
    "        # otherwise update v_curr and improve policy pointwise\n",
    "        v_curr = v_new.copy()\n",
    "\n",
    "        # pointwise improvement: skip boundaries j=0 and j=N-1\n",
    "        for j in range(1, N - 1):\n",
    "            # alpha_sign from last evaluation is used to choose upwind stencil\n",
    "            alpha_sign = alpha_n[j]\n",
    "\n",
    "            # bounds: example simple bounds (adjust to your economic constraints)\n",
    "            pi_bounds = (-5.0, 5.0)    # example: allow leverage\n",
    "            c_bounds = (0.0, 1e6)      # consumption non-negative and capped\n",
    "            bounds = [pi_bounds, c_bounds]\n",
    "\n",
    "            # initial guess for this node\n",
    "            x0 = curr_policy[j, :].copy()\n",
    "\n",
    "            res = minimize(\n",
    "                local_H,\n",
    "                x0,\n",
    "                args=(v_curr[j - 1], v_curr[j], v_curr[j + 1], alpha_sign, w[j], t_curr),\n",
    "                method=\"L-BFGS-B\",\n",
    "                bounds=bounds,\n",
    "                options={\"maxiter\": 100}\n",
    "            )\n",
    "\n",
    "            curr_policy[j, :] = res.x\n",
    "\n",
    "    else:\n",
    "        # if loop completes without break (no convergence)\n",
    "        # store last iterate anyway\n",
    "        v[idx - 1, :] = v_curr\n",
    "        optimal_policy[idx - 1, :, :] = curr_policy\n",
    "        print(f\"did not converge. Last sup_norm {sup_norm}\")\n",
    "\n",
    "# end time loop\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse import diags, lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "#Wealth grid \n",
    "w_max = 1e8\n",
    "N = 1000\n",
    "w = np.linspace(0,w_max,N)\n",
    "dw = w_max/N\n",
    "\n",
    "#Time grid \n",
    "T = 100\n",
    "t0 = 20\n",
    "dt = 0.1\n",
    "t = np.arange(t0, T, dt)\n",
    "\n",
    "#Constants \n",
    "gamma = 0.5\n",
    "r = 0.03\n",
    "rho = 0.03\n",
    "sigma = 0.2\n",
    "mu = 0.05\n",
    "\n",
    "#policy iteration constants\n",
    "max_iter = 10\n",
    "tol = 1e-6\n",
    "\n",
    "#Bequest function \n",
    "def B(w,T):\n",
    "    return np.array(N)\n",
    "\n",
    "#Utility function\n",
    "def U_func(c, t): \n",
    "    return np.exp(-rho*t)*c**(1-gamma)/(1-gamma)\n",
    " \n",
    "def alpha(w, pi, c):\n",
    "    \"Returns advection coefficient for a fixed policy at the grid points.\"\n",
    "    return r - (mu-r)*pi - c\n",
    "\n",
    "def d(w,pi,c):\n",
    "    \"Returns diffusion coefficient for a fixed policy at the grid points.\"\n",
    "    return 0.5*(sigma**2)*(w**2)*(pi**2)\n",
    "\n",
    "def theta(pi, c, t): \n",
    "    \"Returns constant coefficient for a fixed policy evaluated at the grid points.\"\n",
    "    return np.exp(-t*rho)*U(c, t)\n",
    "\n",
    "#In order to solve for the previous time step we need to solve a linear equation we construct the matrix M \n",
    "def M_func(alpha, d):\n",
    "\n",
    "    M_2 = 1 - dt*(np.abs(alpha)/dw - 2*d/(dw**2))\n",
    "    M_1 = np.zeros(N)\n",
    "    M_3 = np.zeros(N)\n",
    "    mask_neg = alpha < 0\n",
    "    mask_pos = alpha > 0\n",
    "    M_1[mask_neg] = -dt * (alpha[mask_neg]/dw + d[mask_neg]/(dw**2))\n",
    "    M_3[mask_neg] = -dt * (d[mask_neg]/(dw**2))  \n",
    "    \n",
    "    M_1[mask_pos] = -dt * (d[mask_pos]/(dw**2))\n",
    "    M_3[mask_pos] = -dt * (d[mask_pos]/(dw**2) - alpha[mask_pos]/dw)\n",
    "    \n",
    "    # build tridiagonal sparse matrix\n",
    "    M = diags(\n",
    "        diagonals=[M_1[1:], M_2, M_3[:-1]],\n",
    "        offsets=[-1, 0, 1],\n",
    "        format='lil'\n",
    "    )\n",
    "\n",
    "    #adjust for boundary conditions \n",
    "    M[0,:] = 0\n",
    "    M[0,0] = 1\n",
    "    M[-1,:] = 0\n",
    "    M[-1, -3:] = [-3, 4, -1]\n",
    "    return M.tocsr()\n",
    "\n",
    "#local hamiltonian used in pointwise minimisation\n",
    "def local_H(policy, v_left, v_centre, v_right, alpha_nj, w_j, t):\n",
    "    if alpha_n[j] < 0:\n",
    "        Dup = (v_right-v_centre)/dw\n",
    "    else: \n",
    "        Dup = (v_centre-v_left)/dw\n",
    "    D_xx = (v_right-2*v_centre+v_left)/dw**2\n",
    "    alpha_j = alpha(w_j, policy[0], policy[1])\n",
    "    d_j = d(w_j, policy[0],policy[1])\n",
    "    theta_j = theta(policy[0], policy[1], t)\n",
    "    return - (Dup*alpha_j +D_xx*d_j + theta_j)\n",
    "\n",
    "\n",
    "v = np.empty([len(t),N])\n",
    "#the row representing the last time step should be initialised with a bequest function in this case we set to zero\n",
    "v[-1,N] = B(w,T)\n",
    "\n",
    "#a 3d policy array where the last dimension is has values for pi(W,t),c(W,t)\n",
    "optimal_policy = np.empty([len(t),N,2])\n",
    "\n",
    "for i in range(len(t)):\n",
    "    idx = len(t)-i-1\n",
    "    vk = v[idx,:]\n",
    "    v_curr = v[idx-1,:]\n",
    "\n",
    "    #The policy iteration loop\n",
    "    curr_policy = np.zeros([N, 2])\n",
    "    t_curr = t[idx]\n",
    "    for _ in range(max_iter):\n",
    "        pi_n = curr_policy[:,0]\n",
    "        c_n = curr_policy[:,1]\n",
    "\n",
    "        #for a given policy we set up the linear system \n",
    "        alpha_n = alpha(w, pi_n, c_n)\n",
    "        d_n = d(w, pi_n, c_n)\n",
    "        M_n = M_func(alpha_n,d_n)\n",
    "        U_n = U_func(c_n, t_curr)\n",
    "\n",
    "        #we solve the system to get the iteration \n",
    "        v_n = spsolve(M_n,vk + U_n)\n",
    "\n",
    "        #we check whether we have convergence \n",
    "        if np.linalg.norm(v_curr-v_n, ord=np.inf) < tol:\n",
    "            v[idx-1,:] = v_n\n",
    "            optimal_policy[idx-1, :, :] = curr_policy\n",
    "            break\n",
    "        else: \n",
    "            v_curr = v_n\n",
    "            for j in range(1,N-1):\n",
    "                res = minimize(\n",
    "                    local_H,\n",
    "                    curr_policy[j,:],\n",
    "                    args=(v_curr[j-1],v_curr[j],v_curr[j+1], alpha_n[j],w[j], t[idx]),\n",
    "                    method=\"BFGS\"\n",
    "                    )\n",
    "                curr_policy[j,:] = res.x\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
